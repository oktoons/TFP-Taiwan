# -*- coding: utf-8 -*-
"""CNN-LSTM on github.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zPcU-drAAf4Qi8EQOttjYmCn2ESdJQAl
"""

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)
root_dir = "/content/gdrive/My Drive/"
dataset_dir = root_dir+"/Colab Notebooks/"

import pandas as pd

df = pd.read_csv(dataset_dir + '/datasets/3-Features_WindSpeed_Humidity.csv')
df

# Make sure GPU is running

import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

# Testing For High RAM
from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
  print('Not using a high-RAM runtime')
else:
  print('You are using a high-RAM runtime!')

def return_rmse(test,predicted):
    rmse = math.sqrt(mean_squared_error(test, predicted))
    print("The root mean squared error is {}.".format(rmse))

def plot_prediction(test,pred):
    plt.figure(figsize=(16,3))
    plt.plot(test, color='red',label='Grount Truth')
    plt.plot(pred, color='blue',label='Predicted')
    plt.title('MV-MS-CNN-LSTM-VT31-3-Feature')
    plt.xlabel('Time')
    plt.ylabel('Number of Vehicle')
    plt.legend()
    plt.savefig(dataset_dir + '/5. CNN_LSTM/image/MV-MS-LSTM-VT31-3-Feature-01.jpg')
    plt.show()

# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, TimeDistributed
from tensorflow.keras.optimizers import SGD
import math
from sklearn.metrics import mean_squared_error
from tensorflow.keras.utils import plot_model
import os
os.environ["CUDA_VISIBLE_DEVICES"]="7"
tf_device='/gpu:7'

df.shape

type(df)

df.dtypes

df = df.to_numpy()

df

df.shape

df[1].dtype

"""# **Preparing Data**"""

# we create a data structure with ni=72 timesteps, no=24 output
# so for each element of training set, we have n previous training set elements
ni = 168
no = 168
n_feature = 3 #Features yang digunakan 14 tidak termasuk holiday

x_data = []
y_data = []
# create ground truth data
y_truth = []
for i in range(ni,len(df)-no):
    x_data.append(df[i-ni:i])
    y_data.append(df[i:i+no,0])
    y_truth.append(df[i,0])
x_data, y_data, y_truth = np.array(x_data), np.array(y_data), np.array(y_truth)

y_truth = np.reshape(y_truth, (y_truth.shape[0]))
print('x_data: ', x_data.shape)
print('y_data: ', y_data.shape)
print('y_truth: ', y_truth.shape)

"""# **Preparing Training and Testing Data**"""

# determine ratio of training:total_data
# split = [0.5, 0.6, 0.7, 0.8, 0.9]
split = [0.7]
e_split = np.round(0.1*x_data.shape[0],0).astype(int)
# Reshaping X_train for efficient modelling khusus LSTM
# split the data
x_train = []
y_train = []
x_test = []
y_test = []
y_gt = []
for i in range(len(split)):
    n_split = np.round(split[i]*x_data.shape[0],0).astype(int)
    x_train.append(x_data[:n_split])
    y_train.append(y_data[:n_split])
    x_test.append(x_data[n_split:n_split+e_split])
    y_test.append(y_data[n_split:n_split+e_split])
    y_gt.append(y_truth[n_split:n_split+e_split])
    print('x_train: ',x_train[i].shape)
    print('y_train: ',y_train[i].shape)
    print('x_test: ',x_test[i].shape)
    print('y_test: ',y_test[0].shape)
    print('y_truth: ',y_gt[i].shape)

"""# **CNN-LSTM Proposed Model**"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import RepeatVector
from tensorflow.keras.layers import TimeDistributed
from tensorflow.keras.layers import Conv1D
from tensorflow.keras.layers import MaxPooling1D

# define model
model = Sequential()
model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(ni,n_feature)))
model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(RepeatVector(no))
model.add(LSTM(no, return_sequences=True))
model.add(Dropout(0.2))
model.add(TimeDistributed(Dense(no)))
model.add(TimeDistributed(Dense(1)))
model.compile(optimizer='adam',loss='mean_squared_error', metrics='mae')
model.summary()

"""# TRAINING"""

from tensorflow.keras.callbacks import EarlyStopping
# simple early stopping
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)

history = []
for i in range(len(split)):
    training=model.fit(x_train[i], y_train[i], epochs=100, batch_size=100, verbose=2, validation_data=(x_test[i],y_test[i]), callbacks=[es])
    history.append(training)
for i in range(len(split)):
    print('mae, mse: ', history[i].history['val_mae'][-1], history[i].history['val_loss'][-1])

"""# SAVE MODEL"""

from tensorflow.keras.models import load_model
model.save(dataset_dir + "/5. CNN_LSTM/model/MV-MS-CNN-LSTM-VT31-3-Feature-VT-31-01.h5")

"""# LAOD MODEL"""

model = load_model(dataset_dir + "/5. CNN_LSTM/model/MV-MS-CNN-LSTM-VT31-3-Feature-VT-31-01.h5")
# test index determine which index of test data that will be usemv-ms-cnnlstm-VT31-VT32-18Featuresd to simulate the predictions
test_index = 50
# how many days ahead that will be predicted
days_ahead = 1
x_test_rpt = x_test [0][test_index]
x_test_rpt = np.reshape(x_test_rpt, (1, x_test_rpt.shape[0],x_test_rpt.shape[1]))
y_out = np.empty([0])
for i in range(days_ahead):
    y_pred = model.predict(x_test_rpt)
    x_test_rpt = np.delete(x_test_rpt, np.s_[:no], axis=1)
    x_test_rpt = np.append(x_test_rpt, y_pred)
    x_test_rpt = np.reshape(x_test_rpt, (1, x_test_rpt.shape[0],1))
    y_out = np.append(y_out, y_pred)

print(y_out.shape)
print(y_gt[0][test_index:len(y_out)+test_index].shape)

"""# EVALUATION MODEL"""

# skalakan range(0-1)
sc = MinMaxScaler(feature_range=(0,1))

series0 = np.expand_dims(y_gt[0][test_index:len(y_out)+test_index], axis = 1)
series1 = np.expand_dims(y_out, axis = 1)

series0 = sc.fit_transform(series0)  #tambahan
series0 = sc.inverse_transform(series0)

series1 = sc.fit_transform(series1) #tambahan
series1 = sc.inverse_transform(series1)

save = np.concatenate((series0, series1), axis=1)
print(save.shape)
np.savetxt(dataset_dir + '/5. CNN_LSTM/output/MV-MS-CNN-LSTM-VT31-3-Feature-VT-31-01.csv', save, delimiter=',')

series0, series1 = np.reshape(series0, (series0.shape[0])), np.reshape(series1, (series1.shape[0]))
print(series0.shape)
print(series1.shape)
plot_prediction(series0,series1)

from sklearn.metrics import r2_score

r2 = r2_score(series0, series1)
print('r2: ',r2)