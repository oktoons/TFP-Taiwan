# -*- coding: utf-8 -*-
"""LSTM-BiLSTM on github.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pUbjX5F0EhHp8-SxdJ055_VUYYis8RPy
"""

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)
root_dir = "/content/gdrive/My Drive/"
dataset_dir = root_dir+"/Colab Notebooks/"

import pandas as pd

data = pd.read_csv(dataset_dir + '/datasets/3-Features_WindSpeed_Humidity.csv')
data

# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, TimeDistributed
from tensorflow.keras.optimizers import SGD
import math
from sklearn.metrics import mean_squared_error
from tensorflow.keras.utils import plot_model
import os
os.environ["CUDA_VISIBLE_DEVICES"]="6"
tf_device='/gpu:6'

def return_rmse(test,predicted):
    rmse = math.sqrt(mean_squared_error(test, predicted))
    print("The root mean squared error is {}.".format(rmse))

def plot_prediction(test,pred):
    plt.figure(figsize=(16,3))
    plt.plot(test, color='red',label='Grount Truth')
    plt.plot(pred, color='blue',label='Predicted')
    plt.title('MV-MS-LSTM-VT31-3-Feature_VT-31')
    plt.xlabel('Time')
    plt.ylabel('Number of Vehicle')
    plt.legend()
    plt.savefig(dataset_dir + '/3. LSTM_BILSTM/image/MV-MS-LSTM-BILSTM-VT31-3-Feature-01.jpg')
    plt.show()

data=data.to_numpy()

data

"""# **Preparing for The Data**"""

# Data requirement

n_input = 168
n_output = 168
n_feature = 3

x_data = []
y_data = []

# create ground turth data
y_truth = []

for i in range(n_input, len(data)- n_output): # i start from 168 until rowData - 168 (26280-168)
    x_data.append(data[i - n_input : i])      # x_data start from 0 until 168, next from 1 until 169, 2 until 170
    y_data.append(data[i : i + n_output,0])   # y_data start from 168 until 336
    y_truth.append(data[i,0])
x_data, y_data, y_truth = np.array(x_data), np.array(y_data), np.array(y_truth)
y_truth = np.reshape(y_truth, (y_truth.shape[0]))
print("x_data", x_data.shape)
print("y_data", y_data.shape)
print("y_truth", y_truth.shape)

"""# **Training and Testing Data**"""

# Bagian ini hanya difungsikan untuk mengetahui apakah program spliting berjalan dengan baik
# SPLIT INTO TRAINING AND TESTING DATA

split = [0.7]
e_split = np.round(0.1*x_data.shape[0],0).astype(int)

# reshaping x_train for efficient modeling specially in LSTM
x_train = []
y_train = []
x_test = []
y_test = []
y_gT = []

for i in range (len(split)):
    n_split = np.round(split[i]*x_data.shape[0],0).astype(int)      # index dimulai dari 0 = 0.5, 1 = 0.6 dst dikali jumlah total data 25944
    x_train.append(x_data[:n_split])
    y_train.append(y_data[:n_split])
    x_test.append(x_data[n_split:n_split+e_split])
    y_test.append(y_data[n_split:n_split+e_split])
    y_gT.append(y_truth[n_split:n_split+e_split])
    print('x_train', x_train[i].shape)
    print('y_train', y_train[i].shape)
    print('x_test', x_test[i].shape)
    print('y_test', y_test[0].shape)
    print('y_truth', y_gT[i].shape)

"""# **Proposed Model**"""

# Membuat model yang akan digunakan untuk dimasukan inputan data
#Ibaratnya sedang membuat template model


# Build a Model following paper number 3 / MV-MS-LSTM-BILSTM-All-Vehicle-5Features-All-VT-Type-NewCodeStyle-FollowPaper.h5

# The LSTM architecture
model = Sequential()

# First LSTM layer with Dropout regularisation
model.add(LSTM(units=n_input, return_sequences=True, input_shape=(n_input,n_feature)))
# model.add(Dropout(0.2))

# Second LSTM_BILSTM layer
model.add(Bidirectional(LSTM(units=n_input, return_sequences=True)))
model.add(Dropout(0.2))

# Third LSTM layer
model.add(LSTM(units=n_input))
model.add(Dropout(0.2))

# The output layer
# model.add(Dense(3))
# model.add(Activation("linear"))
model.add(Dense(units=n_output))
print(model.summary())

# Compiling the RNN
model.compile(optimizer='adam',loss='mean_squared_error', metrics='mae')

"""# **Training Phase**"""

# Model yang sudah dibuat dilakukan proses training dari data yang sudah displit sebelumnya
# Setelah di training model langsung melakukan proses validasi

from tensorflow.keras.callbacks import EarlyStopping
# simple early stopping
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)
    # eearlystopping parameter information:
    # patience = number of epochs with no improvement after which training will be stopped
    # monitor = quantitiy to be monitored
    # mode = auto/min/max : min(training will stop when quantity monitored has stopped decreasing)
        # max ( when quantitiy monitored increasing)

# Training Process
history = [] # menyiapkan wadah untuk menyimpan hasil training
for i in range(len(split)):  # dilakuan 1-1 sesuai dengan spliting data yang sudah ada diatas (0.5, 0.6 - 0.9)
    training=model.fit(
        x_train[i], y_train[i],
        epochs=100,
        batch_size=100,
        verbose=2,
        validation_data=(x_test[i],y_test[i]),callbacks=[es]) #bagian ini adalah proses validasi
    history.append(training)        # hasil training dimasukkan kedalam history

for i in range(len(split)):
    print('mae, mse: ', history[i].history['val_mae'][-1], history[i].history['val_loss'][-1])

"""# SAVE MODELS"""

from tensorflow.keras.models import load_model
model.save(dataset_dir + '/3. LSTM_BILSTM/model/MV-MS-LSTM-BILSTM-VT31-3-Feature-01.h5')

"""# LOAD MODEL"""

model = load_model(dataset_dir + '/3. LSTM_BILSTM/model/MV-MS-LSTM-BILSTM-VT31-3-Feature-01.h5')
# test index determine which index of test data that will be used to simulate the predictions

test_index = 50

# how many days ahead that will be predicted
days_ahead = 1

x_test_rpt = x_test [0][test_index]                                  # chosing data on x_test [0][50], row 0 colom 50 (Mengambil data test di index ke 50 untuk diuji)
x_test_rpt = np.reshape(x_test_rpt, (1, x_test_rpt.shape[0],x_test_rpt.shape[1]))   # make sure the shape is correct as expected
y_out = np.empty([0])                                                # menyiapkan wadah penyimpanan hasil prediksi y_out adalah wadah untuk y_pred
for i in range(days_ahead):
    y_pred = model.predict(x_test_rpt)                               # melakukan proses prediksi pada model yang sudah dibuat pada data test yang sudah dipilih
    x_test_rpt = np.delete(x_test_rpt, np.s_[:n_output], axis=1)     # menghapus bagian awal dari x_test_rpt sebanyak n_output = 168
    x_test_rpt = np.append(x_test_rpt, y_pred)                       # menambahkan prediksi terbaru ke x_test_rpt
    x_test_rpt = np.reshape(x_test_rpt, (1, x_test_rpt.shape[0],1))  # mempertahankan bentuk ukuran x_test_rpt seperti yang diharpkan (expected)
    y_out = np.append(y_out, y_pred)                                 # menambahkakan prediksi baru ke y_out

print(y_out.shape)                                                   # melihat ukuran dari y_out hasil prediksi
print(y_gT[0][test_index:len(y_out)+test_index].shape)               # mencetak bentuk dari nilai y_gT untuk rentang  indeks yang sesuai dengan prediksi

# skalakan range(0-1)
sc = MinMaxScaler(feature_range=(0,1))

"""# EVALUATION"""

series0 = np.expand_dims(y_gT[0][test_index:len(y_out)+test_index], axis = 1)  # data Ground Truth axis=1 basis row, axis = 0 basis colom / menambahkan dimensi baru ke array
series1 = np.expand_dims(y_out, axis = 1)                                      # data hasil prediksi untuk rentang prediksi diperluas sepanjang sumbu 1 (row)

series0 = sc.fit_transform(series0)                             # data series0 yang sudah di sc datanya ditransformasikan (posisinya)
series0 = sc.inverse_transform(series0)                         # mengiversi transofrmasi untuk mengembalikan data ke aslinya

series1 = sc.fit_transform(series1)                             # data series1 yang sudah di sc datanya ditransformasikan (posisinya)n
series1 = sc.inverse_transform(series1)                         # mengiversi transofrmasi untuk mengembalikan data ke aslinya

save = np.concatenate((series0, series1), axis=1)               # data ditumpuk antara series0 dan series1 pada sumbu kolom (berbentuk 2 kolom)
print(save.shape)
np.savetxt(dataset_dir + '/3. LSTM_BILSTM/output/MV-MS-LSTM-BILSTM-VT31-3-Feature-01.csv', save, delimiter=',')

series0, series1 = np.reshape(series0, (series0.shape[0])), np.reshape(series1, (series1.shape[0])) # mengubah series 0 dan series 1 menjadi array 1 dimensi
print(series0.shape)
print(series1.shape)
plot_prediction(series0,series1)

from sklearn.metrics import r2_score
r2 = r2_score(series0, series1)
print('r2: ',r2)